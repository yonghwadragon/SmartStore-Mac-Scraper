# smartstore_review_scraper.py

import time
import pandas as pd
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright


# ================================
# ë¦¬ë·° ì¹´ë“œ íŒŒì‹±
# ================================
def parse_review_card(card):

    # ë‹‰ë„¤ì„
    nickname_el = card.select_one(".Db9Dtnf7gY strong")
    nickname = nickname_el.get_text(strip=True) if nickname_el else ""

    # ë‚ ì§œ
    date_el = card.select_one(".Db9Dtnf7gY span:nth-of-type(1)")
    date = date_el.get_text(strip=True) if date_el else ""

    # í‰ì 
    rating_el = card.select_one("em.n6zq2yy0KA")
    rating = rating_el.get_text(strip=True) if rating_el else ""

    # ì˜µì…˜ (ë§¨ ì²« ì¤„ë§Œ)
    option = ""
    option_box = card.select_one(".b_caIle8kC")
    if option_box:
        all_texts = list(option_box.stripped_strings)
        option = all_texts[0] if all_texts else ""

    # êµ¬ë§¤ì ì •ë³´
    buyer_el = card.select_one(".eWRrdDdSzW")
    buyer_info = buyer_el.get_text(" ", strip=True) if buyer_el else ""

    # ìë™ ë¼ë²¨
    label_el = card.select_one(".h8uqAeqIe7")
    label_info = label_el.get_text(" ", strip=True) if label_el else ""

    auto_label = " | ".join(x for x in [buyer_info, label_info] if x)

    # ë³¸ë¬¸
    content = ""
    content_box = card.select_one(".KqJ8Qqw082")
    if content_box:
        spans = content_box.select("span")

        # ëª¨ë“  span ì¤‘ ë§ˆì§€ë§‰ì„ 'ë³¸ë¬¸'ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ 
        # ë§ˆì§€ë§‰ ì´ì „ spanë“¤ì€ ëª¨ë‘ íƒœê·¸(í•œë‹¬ì‚¬ìš©, ì¬êµ¬ë§¤ ë“±)
        if len(spans) >= 2:
            tags = [s.get_text(strip=True) for s in spans[:-1]]     # í•œë‹¬ì‚¬ìš©, ì¬êµ¬ë§¤ ë“±
            body = spans[-1].get_text(" ", strip=True)               # ì‹¤ì œ ë³¸ë¬¸
            content = " ".join(tags + [body])
        elif len(spans) == 1:
            content = spans[0].get_text(" ", strip=True)


    # ì´ë¯¸ì§€ ê°œìˆ˜
    image_count = 0
    img_box = card.select_one(".s30AvhHfb0")

    if img_box:
        count_span = img_box.select_one(".lOzR1kO8jf")
        if count_span:
            number = "".join(c for c in count_span.get_text(strip=True) if c.isdigit())
            if number:
                image_count = int(number)
        else:
            imgs = img_box.select("img")
            if len(imgs) >= 1:
                image_count = 1

    return {
        "nickname": nickname,
        "date": date,
        "rating": rating,
        "option": option,
        "auto_label": auto_label,
        "content": content,
        "image_count": image_count,
    }


# ================================
# ë¦¬ë·°íƒ­ í´ë¦­ + iframe ìë™ íƒì§€
# ================================
def load_review_frame(page):

    print("ğŸ” ë¦¬ë·°íƒ­ íƒìƒ‰ ì¤‘â€¦")

    # ë¦¬ë·°íƒ­ ë³´ì¼ ë•Œê¹Œì§€ ìŠ¤í¬ë¡¤
    for _ in range(40):
        btn = page.locator('[data-name="REVIEW"]').first
        if btn.is_visible():
            btn.scroll_into_view_if_needed()
            btn.click()
            print("âœ” ë¦¬ë·°íƒ­ í´ë¦­ ì„±ê³µ")
            break
        page.mouse.wheel(0, 600)
        time.sleep(0.2)
    else:
        print("âŒ ë¦¬ë·°íƒ­ ëª» ì°¾ìŒ")
        return None

    # iframe ì°¾ê¸°
    print("âŒ› ë¦¬ë·° iframe ë¡œë”© ëŒ€ê¸°â€¦")
    for _ in range(80):
        for f in page.frames:
            lower = f.url.lower()
            if ("review" in lower) or ("reviews" in lower) or ("pstatic" in lower):
                print(f"âœ” iframe ê°ì§€ë¨: {f.url}")
                return f
        time.sleep(0.25)

    print("âŒ iframe ê°ì§€ ì‹¤íŒ¨")
    return None


# ================================
# ë¦¬ë·° ì „ì²´ ìˆ˜ì§‘
# ================================
def extract_reviews_to_csv(url, limit_pages=13):
    reviews = []
    seen = set()

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        page = browser.new_page()
        print("â³ í˜ì´ì§€ ì ‘ì† ì¤‘â€¦")
        page.goto(url, timeout=60000)
        time.sleep(3)

        iframe = load_review_frame(page)

        # iframe ì—†ëŠ” êµ¬ë²„ì „ (DOM ì§ì ‘ ë Œë”ë§)
        if iframe is None:
            print("ğŸ‘‰ iframe ì—†ìŒ â†’ êµ¬ë²„ì „ ë¦¬ë·° ë°©ì‹ìœ¼ë¡œ ì „í™˜")
            iframe = page

        for n in range(1, limit_pages + 1):
            print(f"\nğŸ“Œ í˜ì´ì§€ {n} ìˆ˜ì§‘â€¦")

            soup = BeautifulSoup(iframe.content(), "lxml")
            review_cards = soup.select(".IwcuBUIAKf")
            print(f"  - ë¦¬ë·° ê°ì§€: {len(review_cards)}")

            for card in review_cards:
                info = parse_review_card(card)
                key = f"{info['nickname']}|{info['date']}|{info['content'][:20]}"
                if key not in seen:
                    seen.add(key)
                    reviews.append(info)

            # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­
            pagination = iframe.locator(".LiT9lKOVbw")
            next_btn = pagination.locator(f'a:has-text("{n+1}")').first

            if next_btn.count() > 0:
                print(f"â¡ í˜ì´ì§€ {n+1} ì´ë™")
                next_btn.click()
                time.sleep(2)
            else:
                print("â›” ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ")
                break

        browser.close()

    # ì €ì¥
    df = pd.DataFrame(reviews)
    df.to_csv("reviews.csv", index=False, encoding="utf-8-sig")
    print("\n====================================")
    print(f"âœ… ì´ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ: {len(reviews)}")
    print("ğŸ“ reviews.csv ì €ì¥ë¨")
    print("====================================")


if __name__ == "__main__":
    test_url = "https://smartstore.naver.com/contentking/products/10639139232"
    extract_reviews_to_csv(test_url)
