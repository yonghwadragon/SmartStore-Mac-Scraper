import sys
import os
import platform
import time
import pandas as pd
import threading
import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright

# =================================================================
# [í•µì‹¬] OSë³„ ë¸Œë¼ìš°ì € ì„¤ì¹˜ ê²½ë¡œ ìë™ ì„¤ì • (ë§¥ë¶ í˜¸í™˜ì„± í•´ê²°)
# =================================================================
def get_browser_path():
    """OSì— ë”°ë¼ ì•ˆì „í•œ ë¸Œë¼ìš°ì € ì„¤ì¹˜ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    system_os = platform.system()
    
    if system_os == 'Darwin':  # Mac OS
        # ë§¥ë¶ì€ ì•± ë‚´ë¶€ê°€ ì•„ë‹Œ, ì‚¬ìš©ì ë¼ì´ë¸ŒëŸ¬ë¦¬ í´ë”('Application Support')ì— ì €ì¥í•´ì•¼ ì•ˆì „í•¨
        user_home = os.path.expanduser("~")
        base_path = os.path.join(user_home, "Library", "Application Support", "SmartStoreScraper")
    else:  # Windows / Linux
        # ìœˆë„ìš°ëŠ” ì‹¤í–‰ íŒŒì¼(exe)ì´ ìˆëŠ” í´ë”ì— 'browsers' í´ë” ìƒì„±
        if getattr(sys, 'frozen', False):
            base_path = os.path.dirname(sys.executable)
        else:
            base_path = os.path.dirname(os.path.abspath(__file__))

    # ìµœì¢… ë¸Œë¼ìš°ì € í´ë” ê²½ë¡œ
    browser_folder = os.path.join(base_path, "browsers")
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„± (ê¶Œí•œ ì—ëŸ¬ ë°©ì§€)
    try:
        os.makedirs(browser_folder, exist_ok=True)
    except Exception as e:
        print(f"âŒ í´ë” ìƒì„± ì‹¤íŒ¨: {e}")
        
    return browser_folder

# í™˜ê²½ ë³€ìˆ˜ ê°•ì œ ì§€ì • (Playwrightê°€ ì´ ê²½ë¡œë¥¼ ë°”ë¼ë³´ê²Œ í•¨)
BROWSER_FOLDER = get_browser_path()
os.environ["PLAYWRIGHT_BROWSERS_PATH"] = BROWSER_FOLDER

# =================================================================
# [ê¸°ëŠ¥] ì‚¬ëŒì²˜ëŸ¼ ìŠ¤í¬ë¡¤ ë‚´ë¦¬ê¸° (ì§€ì—° ë¡œë”© ë°ì´í„° ìˆ˜ì§‘ìš©)
# =================================================================
def smooth_scroll(target_frame, steps=10, delay=0.2):
    """í˜ì´ì§€ë¥¼ ì¡°ê¸ˆì”© ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤í•˜ì—¬ ì´ë¯¸ì§€ì™€ ë¦¬ë·°ë¥¼ ë¡œë”©ì‹œí‚´"""
    try:
        for _ in range(steps):
            target_frame.evaluate("window.scrollBy(0, 800)")
            time.sleep(delay)
    except Exception:
        pass

# =================================================================
# [GUI] ë©”ì¸ í™”ë©´ í´ë˜ìŠ¤
# =================================================================
class ScraperGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë¦¬ë·° ìˆ˜ì§‘ê¸° (Mac/Win í˜¸í™˜)")
        self.root.geometry("600x550")
        self.root.resizable(False, False)

        # ìŠ¤íƒ€ì¼ ì„¤ì •
        style = ttk.Style()
        style.configure("TLabel", font=("Malgun Gothic", 10))
        style.configure("TButton", font=("Malgun Gothic", 10, "bold"))

        # 1. ì…ë ¥ í”„ë ˆì„
        input_frame = ttk.LabelFrame(root, text="ìˆ˜ì§‘ ì„¤ì •", padding=(10, 10))
        input_frame.pack(fill="x", padx=10, pady=10)

        # URL ì…ë ¥
        ttk.Label(input_frame, text="ìƒí’ˆ URL:").grid(row=0, column=0, sticky="w", pady=5)
        self.url_entry = ttk.Entry(input_frame, width=50)
        self.url_entry.grid(row=0, column=1, padx=5, pady=5)

        # í˜ì´ì§€ ìˆ˜ ì…ë ¥
        ttk.Label(input_frame, text="ìˆ˜ì§‘ í˜ì´ì§€ ìˆ˜:").grid(row=1, column=0, sticky="w", pady=5)
        self.limit_entry = ttk.Entry(input_frame, width=10)
        self.limit_entry.insert(0, "13") 
        self.limit_entry.grid(row=1, column=1, sticky="w", padx=5, pady=5)

        # ì‹œì‘ ë²„íŠ¼
        self.start_btn = ttk.Button(input_frame, text="ìˆ˜ì§‘ ì‹œì‘", command=self.start_thread)
        self.start_btn.grid(row=2, column=0, columnspan=2, pady=10, sticky="ew")

        # 2. ë¡œê·¸ í”„ë ˆì„
        log_frame = ttk.LabelFrame(root, text="ì§„í–‰ ìƒí™©", padding=(10, 10))
        log_frame.pack(fill="both", expand=True, padx=10, pady=5)

        self.log_text = scrolledtext.ScrolledText(log_frame, height=15, state='disabled', font=("Consolas", 9))
        self.log_text.pack(fill="both", expand=True)

        # ì´ˆê¸° ì•ˆë‚´ ë©”ì‹œì§€
        self.log("í”„ë¡œê·¸ë¨ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        self.log(f"ğŸ“‚ ë¸Œë¼ìš°ì € ì €ì¥ ê²½ë¡œ: {BROWSER_FOLDER}")
        self.log("ğŸ‘‰ URLì„ ì…ë ¥í•˜ê³  [ìˆ˜ì§‘ ì‹œì‘]ì„ ëˆ„ë¥´ì„¸ìš”.")

    def log(self, message):
        """ë¡œê·¸ ì°½ì— í…ìŠ¤íŠ¸ ì¶œë ¥"""
        self.log_text.configure(state='normal')
        self.log_text.insert(tk.END, message + "\n")
        self.log_text.see(tk.END)
        self.log_text.configure(state='disabled')

    def start_thread(self):
        """ë²„íŠ¼ í´ë¦­ ì‹œ ì‘ì—… ì“°ë ˆë“œ ì‹œì‘"""
        url = self.url_entry.get().strip()
        limit = self.limit_entry.get().strip()

        if not url:
            messagebox.showwarning("ê²½ê³ ", "URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        if not limit.isdigit():
            messagebox.showwarning("ê²½ê³ ", "í˜ì´ì§€ ìˆ˜ëŠ” ìˆ«ìë§Œ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return

        self.start_btn.config(state="disabled") # ë²„íŠ¼ ì ê¸ˆ
        self.log("\n[ì‘ì—… ì‹œì‘] --------------------------------")
        
        # UI ë©ˆì¶¤ ë°©ì§€ë¥¼ ìœ„í•´ ë³„ë„ ì“°ë ˆë“œì—ì„œ ì‹¤í–‰
        t = threading.Thread(target=self.run_scraper, args=(url, int(limit)))
        t.daemon = True
        t.start()

    def run_scraper(self, url, limit_pages):
        try:
            # ë¸Œë¼ìš°ì € ì„¤ì¹˜ í™•ì¸
            self.install_browser_if_needed()
            
            # í¬ë¡¤ë§ ì‹œì‘
            extract_reviews_to_csv(self, url, limit_pages)
            
            messagebox.showinfo("ì™„ë£Œ", "ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\nreviews.csv íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        except Exception as e:
            self.log(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
            messagebox.showerror("ì—ëŸ¬", f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n{e}")
        finally:
            self.start_btn.config(state="normal") # ë²„íŠ¼ ì ê¸ˆ í•´ì œ

    def install_browser_if_needed(self):
        self.log("âš™ï¸ ë¸Œë¼ìš°ì € ì—”ì§„ ìƒíƒœ í™•ì¸ ì¤‘...")
        try:
            # ì„¤ì¹˜ëœ ë¸Œë¼ìš°ì €ê°€ ìˆëŠ”ì§€ í…ŒìŠ¤íŠ¸
            with sync_playwright() as p:
                p.chromium.launch(headless=True).close()
            self.log("âœ… ë¸Œë¼ìš°ì € ì—”ì§„ ì •ìƒ.")
        except Exception:
            self.log("ğŸš€ ë¸Œë¼ìš°ì € ì—”ì§„ì´ ì—†ìŠµë‹ˆë‹¤. ìë™ ì„¤ì¹˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            self.log("   (ì•½ 1~2ë¶„ ì†Œìš”ë©ë‹ˆë‹¤. ë„ì§€ ë§ê³  ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!)")
            try:
                from playwright.__main__ import main
                old_argv = sys.argv
                sys.argv = ["playwright", "install", "chromium"]
                try:
                    main()
                except SystemExit:
                    pass
                finally:
                    sys.argv = old_argv
                self.log("âœ… ë¸Œë¼ìš°ì € ì„¤ì¹˜ ì™„ë£Œ!")
            except Exception as e:
                self.log(f"âŒ ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
                raise e


# =================================================================
# [ë¡œì§] ì›¹ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ë“¤
# =================================================================

def parse_review_card(card):
    """HTML ìš”ì†Œì—ì„œ ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ"""
    nickname_el = card.select_one(".Db9Dtnf7gY strong")
    nickname = nickname_el.get_text(strip=True) if nickname_el else ""

    date_el = card.select_one(".Db9Dtnf7gY span:nth-of-type(1)")
    date = date_el.get_text(strip=True) if date_el else ""

    rating_el = card.select_one("em.n6zq2yy0KA")
    rating = rating_el.get_text(strip=True) if rating_el else ""

    option = ""
    option_box = card.select_one(".b_caIle8kC")
    if option_box:
        all_texts = list(option_box.stripped_strings)
        option = all_texts[0] if all_texts else ""

    buyer_el = card.select_one(".eWRrdDdSzW")
    buyer_info = buyer_el.get_text(" ", strip=True) if buyer_el else ""
    label_el = card.select_one(".h8uqAeqIe7")
    label_info = label_el.get_text(" ", strip=True) if label_el else ""
    auto_label = " | ".join(x for x in [buyer_info, label_info] if x)

    content = ""
    content_box = card.select_one(".KqJ8Qqw082")
    if content_box:
        spans = content_box.select("span")
        if len(spans) >= 2:
            tags = [s.get_text(strip=True) for s in spans[:-1]]
            body = spans[-1].get_text(" ", strip=True)
            content = " ".join(tags + [body])
        elif len(spans) == 1:
            content = spans[0].get_text(" ", strip=True)

    image_count = 0
    img_box = card.select_one(".s30AvhHfb0")
    if img_box:
        count_span = img_box.select_one(".lOzR1kO8jf")
        if count_span:
            number = "".join(c for c in count_span.get_text(strip=True) if c.isdigit())
            if number:
                image_count = int(number)
        else:
            imgs = img_box.select("img")
            if len(imgs) >= 1:
                image_count = 1

    return {
        "nickname": nickname,
        "date": date,
        "rating": rating,
        "option": option,
        "auto_label": auto_label,
        "content": content,
        "image_count": image_count,
    }

def load_review_frame(gui, page):
    """ë¦¬ë·° íƒ­ì„ ì°¾ì•„ì„œ í´ë¦­í•˜ê³  iframe ë¡œë”© ëŒ€ê¸°"""
    gui.log("ğŸ” ë¦¬ë·°íƒ­ íƒìƒ‰ ì¤‘â€¦")
    
    # íƒ­ ì°¾ê¸° ë° í´ë¦­
    for _ in range(40):
        btn = page.locator('[data-name="REVIEW"]').first
        if btn.is_visible():
            btn.scroll_into_view_if_needed()
            time.sleep(0.5)
            btn.click()
            gui.log("âœ” ë¦¬ë·°íƒ­ í´ë¦­ ì„±ê³µ")
            break
        page.mouse.wheel(0, 600)
        time.sleep(0.2)
    else:
        gui.log("âŒ ë¦¬ë·°íƒ­ ëª» ì°¾ìŒ. (ê¸°ë³¸ í˜ì´ì§€ì—ì„œ ê³„ì† íƒìƒ‰)")
        return page

    gui.log("âŒ› ë¦¬ë·° iframe ë¡œë”© ëŒ€ê¸°â€¦")
    for _ in range(80):
        for f in page.frames:
            lower = f.url.lower()
            if ("review" in lower) or ("reviews" in lower) or ("pstatic" in lower):
                gui.log(f"âœ” iframe ê°ì§€ë¨")
                return f
        time.sleep(0.25)
    return page

def load_next_page(gui, target_frame, current_page_num):
    """ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­"""
    next_page_num = current_page_num + 1
    next_btn = target_frame.locator(f'.LiT9lKOVbw a:has-text("{next_page_num}")').first

    if next_btn.count() > 0:
        gui.log(f"â¡ í˜ì´ì§€ {next_page_num} ì´ë™")
        next_btn.click()
        time.sleep(2) # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        return True
    else:
        return False

def extract_reviews_to_csv(gui, url, limit_pages=13):
    """ì „ì²´ ë¦¬ë·° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤"""
    reviews = []
    seen = set()

    with sync_playwright() as p:
        # headless=False: ì‚¬ìš©ìê°€ ë³´ëŠ” ì•ì—ì„œ ë¸Œë¼ìš°ì €ê°€ ì›€ì§ì„
        browser = p.chromium.launch(headless=False)
        page = browser.new_page()
        gui.log(f"â³ í˜ì´ì§€ ì ‘ì† ì¤‘: {url}")
        
        try:
            page.goto(url, timeout=60000)
        except Exception:
            gui.log("âš ï¸ ì ‘ì† ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ê±°ë‚˜ íƒ€ì„ì•„ì›ƒ ë˜ì—ˆìŠµë‹ˆë‹¤. ê³„ì† ì‹œë„í•©ë‹ˆë‹¤.")

        time.sleep(3)

        target_frame = load_review_frame(gui, page)
        
        # iframe ë¡œë“œ ì‹¤íŒ¨ í™•ì¸
        if target_frame is page and target_frame.url == url and page.locator(".IwcuBUIAKf").count() == 0:
            gui.log("âŒ ë¦¬ë·° ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            browser.close()
            return
            
        for n in range(1, limit_pages + 1):
            gui.log(f"ğŸ“Œ í˜ì´ì§€ {n} ìˆ˜ì§‘ ì¤‘â€¦")
            
            # [ì¤‘ìš”] ìŠ¤í¬ë¡¤ì„ ë‚´ë ¤ì„œ ì§€ì—° ë¡œë”©ëœ ë°ì´í„°(ì´ë¯¸ì§€, í…ìŠ¤íŠ¸) í™œì„±í™”
            gui.log("   (ìŠ¤í¬ë¡¤ ë‚´ë¦¬ëŠ” ì¤‘...)")
            smooth_scroll(target_frame, steps=10, delay=0.2)

            soup = BeautifulSoup(target_frame.content(), "lxml")
            review_cards = soup.select(".IwcuBUIAKf")
            
            current_page_reviews = 0
            for card in review_cards:
                info = parse_review_card(card)
                if not info: continue
                
                # ì¤‘ë³µ ë°©ì§€ í‚¤ ìƒì„±
                key = f"{info['nickname']}|{info['date']}|{info['content'][:10]}"
                if key not in seen:
                    seen.add(key)
                    reviews.append(info)
                    current_page_reviews += 1

            gui.log(f"   â”” ì‹ ê·œ: {current_page_reviews}ê±´ (ëˆ„ì : {len(reviews)}ê±´)")
            
            # ë‹¤ìŒ í˜ì´ì§€ ì´ë™
            if not load_next_page(gui, target_frame, n):
                gui.log("â›” ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ")
                break

        browser.close()

    # CSV ì €ì¥
    df = pd.DataFrame(reviews)
    df.to_csv("reviews.csv", index=False, encoding="utf-8-sig")
    gui.log("====================================")
    gui.log(f"âœ… ì´ {len(reviews)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
    gui.log("ğŸ“ reviews.csv ì €ì¥ë¨")

if __name__ == "__main__":
    root = tk.Tk()
    app = ScraperGUI(root)
    root.mainloop()
